<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>ConvNetJS OCR demo</title>
  <meta name="description" content="">
  <meta name="author" content="">


<style>
#visnet {
  display: flex;
  flex-wrap: wrap;
  /*align-items: center;*/
  justify-content: center;
}
.layer {
  border: 1px solid #999;
  margin-bottom: 5px;
  text-align: left;
  padding: 10px;
  display: block;
  width: 600px;
  margin: 5px;
}
.layer_act {
  width: 400px;
  float: right;
}
.ltconv {
  background-color: #FDD;
}
.ltrelu {
  background-color: #FDF;
}
.ltpool {
  background-color: #DDF;
}
.ltsoftmax {
  background-color: #FFD;
}
.ltfc {
  background-color: #DFF;
}
.ltlrn {
  background-color: #DFD; 
}
.ltdropout {
  background-color: #AAA;  
}
.ltitle {
  color: #333;
  font-size: 18px;
}
.actmap {
  margin: 1px;
}
#trainstats {
  text-align: left;
}
.clear {
  clear: both;
}
#wrap {
  /*width: 1000px;
  margin-left: auto;
  margin-right: auto;*/
}
h1 {
  font-size: 16px;
  color: #333;
  background-color: #DDD;
  border-bottom: 1px #999 solid;
  text-align: center;
}
.secpart {
  width: 400px;
  float: left;
}
#lossgraph {
  /*border: 1px solid #F0F;*/
  width: 100%;
}
.probsdiv canvas {
  float: left;
}
.probsdiv {
  height: 60px;
  width: 200px;
  display: inline-block;
  font-size: 12px;
  box-shadow: 0px 0px 2px 2px #EEE;
  margin: 5px;
  padding: 5px;
  color: black;
}
.pp {
  margin: 1px;
  padding: 1px;
  margin-left: 85px; 
}
#testset_acc {
  margin-bottom: 200px;
}
body {
  font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
}
</style>

<script src="jquery-1.8.3.min.js"></script>
<script src="vis.js"></script>
<script src="util.js"></script>
<script src="../convnet.js"></script>
<script>
var c = document.createElement('canvas')
var d = document.createElement('canvas')
c.width = 500
var DIM = 24;
d.width = DIM
d.height = DIM
</script>
<script src="fonts.js"></script>
<script src="single.js"></script>
<div id="blah"></div>
<script>

var startTime = Date.now()

function fafnir(data, optional_name){
  var xhr = new XMLHttpRequest();
  xhr.open('POST', 'http://127.0.0.1:6005/' + (optional_name || ''), true);
  xhr.send(typeof data == "object" ? JSON.stringify(data) : data);
}

var runs = 0;
if(localStorage.ocracy_runs) runs = parseInt(localStorage.ocracy_runs) || 0;
localStorage.ocracy_runs = ++runs;

setInterval(function(){
  var name = "rbf-" + charset + "-run-" + runs;

  var trained_info  = {
    name: name,
    examples_seen: step_num,
    age_minutes: (Date.now() - startTime) / 1000 / 60,
    train_accuracy: trainAccWindow.get_average(),
    validation_accuracy: valAccWindow.get_average()
  };

  fafnir('trained_info = ' +JSON.stringify(trained_info, null, '  ')+';\n\ntrained_symbols = ' + JSON.stringify(symbols) + ';\n\ntrained_network = '+ JSON.stringify(net.toJSON()) + ';\n', name)
}, 60 * 1000)

// var symbols = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLNOPQRSTUVWXYZ0123456789'.split('')

var symbols = " !”#$%&’()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~";
           // " !”#$%&’()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~"

var volumes = []


;(function(){
var rbf = new Image()
rbf.src = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAqAAAAAMCAYAAAC9fQ95AAAEFElEQVR42u1dy3LDIAz0//90e+1kaqN9gXDwTC9xYgNipUUr6PVTvK7r+rmu6/az/+6PnvX37/Pzp3fcvWt0X2131+tuPKv2e7JD9X61LbPft5ON0N85743+2PeN/MYTbtH5WcHzrPFU+rACm7PvoT4b+T7jA9h2OH1D93Yiz+zuj2fZ6219cvf9Uhr45PgrQejTWdx9NiKmyMSvBESHQ+sEAoczcEw8l6OtBLxO4Kxi565Pd7hxB8Cn9ldIk4I3BLMovndx+Gjb37R4ZgmOy9exC8OV/kUZJ+R7zHvfStTe2C8kbqHYG87PbgT07ndOAlr5/PPdrqDhJgyjfiNETg3q1UxaioA6yI3qbNA2oWOWyPYyykFqPA4BPQSUnYuKsrUjAZ317ENA39sv1pciqtp0AqrIRNVJj7Jz5h4rba8in8i4KMSgKqGq2c+qXdi2ucoWlAyOWsKAyuzIMxj8sOOjBH9Ggq/6rJFdWDsoWXEG06vusVhB/UmK0Lvtztxj8Vf1VyppUZWflfhTSkuY+bML/hgCyizmJAKqZMKe6j4ZY6rZLNQRKnKkIzPoII3oqsZBQBO1qlVbOeUHZS4yCzfVaTIrV5QsKHMelXVQZQT1S4p6oARDx0KwQwBUcbYq052qIUbwh2Z1EfKL+E0l4cH4mlX4cxG7HfHnxiyMt1TauUoUlOCfTDePiPLuBDTheKvgdwXVWSv8pMz6X6kHsvBB8aH+bkSYEvOTCRQVn9QtQ6HaMhXI3ES5MwF1ZPad+FMXLLPxh/q6TuQtQfI6409RLW2xdnYG1AUQB3lLGim1M9sd4FnyjDooB9l0ByZVRmfm2q4EtNqnhAT/ZgLqVHwcbUHUBRbTuxDQVfhDT3g4BNRPQFGs7oi/rQioa9X4KQFXsiloPYzL2bmk1mQ7nbWcCbLGEFc3AWVtlKwBVclbdwJaIdGOOa9uUOpMQJVsetU2I2KAZGDQI7EOAfXjrxK3kvibnaFPEtAKjpBx7Yg/tD9u7E2X4NGia4T9p4jdrJ2VCHhUcLicJLNpJp3NZbJIah0TSyRc9bDsgqn6G8VRpXfBI/M/KaW7saIS0GqphLJxQT31wrk4TBPQWTXYqG9H7ZDE3yoC6sCfQiQrZWe74i+5AGxRA4oyekXeZg4vZgfaWauK1Oih8o7jQGvnIfUV56pmHRAbOY8dUXa2I99VdsEzh7wrAdBZV5rYJFDxWR12waPtQTM1jOKhqgWpEhmHmtdpF7xDeXLWdbtrVWfgD1E/HRuduuOvFQFNAFshdwlZJf2eTs/r3NfT7nNVpPwd51CHfiTPr3QqPhUiopLIt2HFNc8O/r4Df0gGOzGGXxl93/avOA+RO9db51R3wvCNh8cjmaJz7WmHg7/vsvuqfy7wC4rGYK0Z/ot2AAAAAElFTkSuQmCC";




var c = document.createElement('canvas')
c.width = 7
c.height = 12
var x = c.getContext('2d')

// document.getElementById('blah').appendChild(rbf)
console.log(symbols.length)
for(var i = 0; i < symbols.length; i++){
  x.drawImage(rbf, -i * 7, 0)

  var things = x.getImageData(0, 0, 7, 12);
  
  var netx = new convnetjs.Vol(7,12,1,0);

  for(var a = 0; a < 12; a++){
    for(var b = 0; b < 7; b++){
      var n = a * 7 + b;
      if(things.data[4 * n] > 128){
        netx.w[n] = 0
      }else{
        netx.w[n] = 1
      }
    }
  }

  // console.log(netx)
  
  volumes[i] = netx;

  var s = new Image;
  s.src = c.toDataURL('image/png')
  s.style.border = '1px solid gray'
  s.style.margin = '2px'
  document.getElementById('blah').appendChild(s)
}



})();


var t = "layer_defs = [];\n\
layer_defs.push({type:'input', out_sx:24, out_sy:24, out_depth:1});\n\
layer_defs.push({type:'conv', sx:5, filters:8, stride:1, pad:2, activation:'relu'});\n\
layer_defs.push({type:'pool', sx:2, stride:2});\n\
layer_defs.push({type:'conv', sx:5, filters:18, stride:1, pad:2, activation:'relu'});\n\
layer_defs.push({type:'pool', sx:5, stride:2});\n\
//layer_defs.push({type:'fc', num_neurons:20, activation:'sigmoid'});\n\
layer_defs.push({type:'regression', num_neurons:7*12});\n\
//layer_defs.push({type:'softmax', num_classes:"+symbols.length+"});\n\
\n\
net = new convnetjs.Net();\n\
net.makeLayers(layer_defs);\n\
\n\
trainer = new convnetjs.SGDTrainer(net, {method:'adadelta', batch_size:20, l2_decay:0.001});\n\
";

var sample_test_instance = function(){
  return sample_training_instance()
}

var num_batches = 21; // 20 training batches, 1 test
var data_img_elts = new Array(num_batches);
var img_data = new Array(num_batches);
var loaded = new Array(num_batches);
var loaded_train_batches = [];

// int main
$(window).load(function() {

  $("#newnet").val(t);
  eval($("#newnet").val());

  update_net_param_display();

  for(var k=0;k<loaded.length;k++) { loaded[k] = false; }

  // load_data_batch(0); // async load train set batch 0 (6 total train batches)
  // load_data_batch(20); // async load test set (batch 6)
  start_fun();
});

var start_fun = function() {
  // if(loaded[0] && loaded[20]) { 
    console.log('starting!'); 
    setInterval(load_and_step, 0); // lets go!
  // }
  // else { setTimeout(start_fun, 200); } // keep checking
}

// var load_data_batch = function(batch_num) {
//   // Load the dataset with JS in background
//   data_img_elts[batch_num] = new Image();
//   var data_img_elt = data_img_elts[batch_num];
//   data_img_elt.onload = function() { 
//     var data_canvas = document.createElement('canvas');
//     data_canvas.width = data_img_elt.width;
//     data_canvas.height = data_img_elt.height;
//     var data_ctx = data_canvas.getContext("2d");
//     data_ctx.drawImage(data_img_elt, 0, 0); // copy it over... bit wasteful :(
//     img_data[batch_num] = data_ctx.getImageData(0, 0, data_canvas.width, data_canvas.height);
//     loaded[batch_num] = true;
//     if(batch_num < 20) { loaded_train_batches.push(batch_num); }
//     console.log('finished loading data batch ' + batch_num);
//   };
//   data_img_elt.src = "mnist/mnist_batch_" + batch_num + ".png";
// }

// ------------------------
// END OCR SPECIFIC STUFF
// ------------------------

var maxmin = cnnutil.maxmin;
var f2t = cnnutil.f2t;

// elt is the element to add all the canvas activation drawings into
// A is the Vol() to use
// scale is a multiplier to make the visualizations larger. Make higher for larger pictures
// if grads is true then gradients are used instead
var draw_activations = function(elt, A, scale, grads) {

  var s = scale || 2; // scale
  var draw_grads = false;
  if(typeof(grads) !== 'undefined') draw_grads = grads;

  // get max and min activation to scale the maps automatically
  var w = draw_grads ? A.dw : A.w;
  var mm = maxmin(w);

  // create the canvas elements, draw and add to DOM
  for(var d=0;d<A.depth;d++) {

    var canv = document.createElement('canvas');
    canv.className = 'actmap';
    var W = A.sx * s;
    var H = A.sy * s;
    canv.width = W;
    canv.height = H;
    var ctx = canv.getContext('2d');
    var g = ctx.createImageData(W, H);

    for(var x=0;x<A.sx;x++) {
      for(var y=0;y<A.sy;y++) {
        if(draw_grads) {
          var dval = Math.floor((A.get_grad(x,y,d)-mm.minv)/mm.dv*255);
        } else {
          var dval = Math.floor((A.get(x,y,d)-mm.minv)/mm.dv*255);  
        }
        for(var dx=0;dx<s;dx++) {
          for(var dy=0;dy<s;dy++) {
            var pp = ((W * (y*s+dy)) + (dx + x*s)) * 4;
            for(var i=0;i<3;i++) { g.data[pp + i] = dval; } // rgb
            g.data[pp+3] = 255; // alpha channel
          }
        }
      }
    }
    ctx.putImageData(g, 0, 0);
    elt.appendChild(canv);
  }  
}



var draw_image_activations = function(elt, A, scale, grads) {

  var s = scale || 2; // scale
  var draw_grads = false;
  if(typeof(grads) !== 'undefined') draw_grads = grads;

  // get max and min activation to scale the maps automatically
  var w = draw_grads ? A.dw : A.w;
  var mm = maxmin(w);


  var canv = document.createElement('canvas');
  canv.className = 'actmap';
  var W = 7;
  var H = 12;
  canv.width = W;
  canv.height = H;
  var ctx = canv.getContext('2d');
  var g = ctx.createImageData(W, H);

  // create the canvas elements, draw and add to DOM
  // for(var d=0;d<A.depth;d++) {
    for(var y = 0; y < H; y++){
    for(var x = 0; x < W; x++){
      
        var d = y * W + x;
    // var x = 0, y = 0;
    // for(var x=0;x<A.sx;x++) {
    //   for(var y=0;y<A.sy;y++) {
        if(draw_grads) {
          var dval = Math.floor((A.get_grad(0,0,d)-mm.minv)/mm.dv*255);
        } else {
          var dval = Math.floor((A.get(0,0,d)-mm.minv)/mm.dv*255);  
        }

        // var dval = Math.floor((Math.min(1, Math.max(-1, A.get(0,0,d))) + 1) / 2 * 255);

        var dval = Math.floor((Math.min(1, Math.max(0, A.get(0,0,d)))) * 255);

        // var dval = Math.floor(*255);  


        g.data[4 * d] = g.data[4 * d + 1] = g.data[4 * d + 2] = dval;
        g.data[4 * d + 3] = 255;

        // for(var dx=0;dx<s;dx++) {
        //   for(var dy=0;dy<s;dy++) {
        //     var pp = ((W * (y*s+dy)) + (dx + x*s)) * 4;
        //     for(var i=0;i<3;i++) { g.data[pp + i] = dval; } // rgb
        //     g.data[pp+3] = 255; // alpha channel
        //   }
        // }



      }
    }
    ctx.putImageData(g, 0, 0);
    canv.style.width = (7 * scale) + 'px'
    canv.style.imageRendering = 'pixelated'
    elt.appendChild(canv);
  // }  
}

var visualize_activations = function(net, elt) {

  // clear the element
  elt.innerHTML = "";

  // show activations in each layer
  var N = net.layers.length;
  for(var i=0;i<N + 1;i++) {

    var L = net.layers[i];

        if(i == N) L = net.layers[0]; // there and back again


    var layer_div = document.createElement('div');

    // visualize activations
    var activations_div = document.createElement('div');
    activations_div.appendChild(document.createTextNode('Activations:'));
    activations_div.appendChild(document.createElement('br'));
    activations_div.className = 'layer_act';
    var scale = 2;
    if(L.layer_type==='softmax' || L.layer_type==='fc' || L.layer_type==='regression'){
    scale = 10; // for softmax
    draw_image_activations(activations_div, L.out_act, scale);
  }else{
    draw_activations(activations_div, L.out_act, scale);
  }
    

    // visualize filters if they are of reasonable size
    if(L.layer_type === 'conv') {
      var filters_div = document.createElement('div');
      if(L.filters[0].sx>3) {
        // actual weights
        filters_div.appendChild(document.createTextNode('Weights:'));
        filters_div.appendChild(document.createElement('br'));
        for(var j=0;j<L.filters.length;j++) {
          draw_activations(filters_div, L.filters[j], 2);
        }
        // gradients
        filters_div.appendChild(document.createElement('br'));
        filters_div.appendChild(document.createTextNode('Gradients:'));
        filters_div.appendChild(document.createElement('br'));
        for(var j=0;j<L.filters.length;j++) {
          draw_activations(filters_div, L.filters[j], 2, true);
        }
      } else {
        filters_div.appendChild(document.createTextNode('Weights hidden, too small'));
      }
      activations_div.appendChild(filters_div);
    }
    layer_div.appendChild(activations_div);

    // print some stats on left of the layer
    layer_div.className = 'layer ' + 'lt' + L.layer_type;
    var title_div = document.createElement('div');
    title_div.className = 'ltitle'
    var t = L.layer_type + ' (' + L.out_sx + 'x' + L.out_sy + 'x' + L.out_depth + ')';
    title_div.appendChild(document.createTextNode(t));
    layer_div.appendChild(title_div);

    if(L.layer_type==='conv') {
      var t = 'filter size ' + L.filters[0].sx + 'x' + L.filters[0].sy + 'x' + L.filters[0].depth + ', stride ' + L.stride;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }
    if(L.layer_type==='pool') {
      var t = 'pooling size ' + L.sx + 'x' + L.sy + ', stride ' + L.stride;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }

    // find min, max activations and display them
    var mma = maxmin(L.out_act.w);
    var t = 'max activation: ' + f2t(mma.maxv) + ', min: ' + f2t(mma.minv);
    layer_div.appendChild(document.createTextNode(t));
    layer_div.appendChild(document.createElement('br'));

    // number of parameters
    if(L.layer_type==='conv') {
      var tot_params = L.sx*L.sy*L.in_depth*L.filters.length + L.filters.length;
      var t = 'parameters: ' + L.filters.length + 'x' + L.sx + 'x' + L.sy + 'x' + L.in_depth + '+' + L.filters.length + ' = ' + tot_params;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }
    if(L.layer_type==='fc') {
      var tot_params = L.num_inputs*L.filters.length + L.filters.length;
      var t = 'parameters: ' + L.filters.length + 'x' + L.num_inputs + '+' + L.filters.length + ' = ' + tot_params;
      layer_div.appendChild(document.createTextNode(t));
      layer_div.appendChild(document.createElement('br'));
    }

    // css madness needed here...
    var clear = document.createElement('div');
    clear.className = 'clear';
    layer_div.appendChild(clear);

    elt.appendChild(layer_div);
  }
}

// loads a training image and trains on it with the network
var paused = false;
var load_and_step = function() {
  if(paused) return; 
  var tGenerate = Date.now()
  var sample = sample_training_instance();
  genAccWindow.add(Date.now() - tGenerate)
  step(sample); // process this image
}

// evaluate current network on test set
var test_predict = function() {
  var num_classes = net.layers[net.layers.length-1].out_depth;

  document.getElementById('testset_acc').innerHTML = '';
  // grab a random test image
  for(num=0;num<100;num++) {
    var sample = sample_test_instance();
    var y = sample.label;  // ground truth label

    // forward prop it through the network
    var aavg = new convnetjs.Vol(1,1,num_classes,0.0);
    // ensures we always have a list, regardless if above returns single item or list
    var xs = [].concat(sample.x);
    var n = xs.length;
    for(var i=0;i<n;i++) {
      var a = net.forward(xs[i]);
      aavg.addFrom(a);
    }
    var preds = [];
    
    // for(var k=0;k<aavg.w.length;k++) {
    //   preds.push({
    //     k:k,
    //     p:aavg.w[k]
    //   }); 
    // }


    for(var k = 0; k < volumes.length; k++){
      var s = 0;
      for(var j = 0; j < 7 * 12; j++){
        var dval = Math.min(1, Math.max(-1, aavg.w[j]));
        s += Math.pow(dval - volumes[k].w[j], 2)
        // s += Math.pow(aavg.w[j] - volumes[k].w[j], 2)
      }
      preds.push({
        k: k,
        p: Math.exp(-Math.sqrt(s/(7 * 12)))
      })
    }




    // console.log(preds)
    preds.sort(function(a,b){return a.p<b.p ? 1:-1;});
    
    var div = document.createElement('div');
    div.className = 'testdiv';

    // draw the image into a canvas
    draw_activations(div, xs[0], 2); // draw Vol into canv

    // console.log(aavg)
    draw_image_activations(div, aavg, 4)

    // add predictions
    var probsdiv = document.createElement('div');
    div.className = 'probsdiv';
    div.style.backgroundColor = (preds[0].k===y) ? 'rgba(85,187,85,0.5)' : 'rgba(187,85,85,0.5)';
    var t = '';
    for(var k=0;k<Math.min(3, symbols.length);k++) {
      var col = preds[k].k===y ? 'rgb(85,187,85)' : 'rgb(187,85,85)';
      var text = symbols[preds[k].k];
      if(text == ' ') text = '&nbsp;';
      // text += '&nbsp;' + (preds[k].p/n).toFixed(5);

      t += '<div class=\"pp\" style=\"width:' + Math.floor(preds[k].p/n*100) + 'px; background-color:' + col + ';\">' + text + '</div>'
    }
    probsdiv.innerHTML = t;
    div.appendChild(probsdiv);
    div.appendChild(document.createTextNode(sample.font + ': ' + symbols[sample.label]))

    // add it into DOM
    $("#testset_acc").append(div).fadeIn(1000);
  }
}


function getPrediction(){
  var result = net.layers[net.layers.length - 1].out_act;

  var min = Infinity, pred = 0;
  for(var k = 0; k < volumes.length; k++){
      var s = 0;
      for(var j = 0; j < 7 * 12; j++){
        
        var dval = Math.min(1, Math.max(-1, result.w[j]));
        s += Math.pow(dval - volumes[k].w[j], 2);
        // s += Math.pow(result.w[j] - volumes[k].w[j], 2)

        

      }
      if(s < min){
        min = s;
        pred = k;
      }
  }

  return pred;

}


var lossGraph = new cnnvis.Graph();
var xLossWindow = new cnnutil.Window(100);
var wLossWindow = new cnnutil.Window(100);
var trainAccWindow = new cnnutil.Window(100);
var valAccWindow = new cnnutil.Window(100);
var genAccWindow = new cnnutil.Window(100);
var timeAccWindow = new cnnutil.Window(100);
var step_num = 0;

var lastStep = Date.now();
var step = function(sample) {
  
  timeAccWindow.add(Date.now() - lastStep)
  lastStep = Date.now();

  var x = sample.x;
  var y = volumes[sample.label].w;

  if(sample.isval) {
    // use x to build our estimate of validation error
    net.forward(x)
    // var yhat = getPrediction();
    var yhat = getPrediction();
    var val_acc = yhat === sample.label ? 1.0 : 0.0;
    valAccWindow.add(val_acc);
    return; // get out
  }

  // train on it with network
  var stats = trainer.train(x, y);
  var lossx = stats.cost_loss;
  var lossw = stats.l2_decay_loss;

  if(Math.random() < 0.1){
    // keep track of stats such as the average training error and loss
    // var yhat = getPrediction();
    var yhat = getPrediction();
    var train_acc = yhat === sample.label ? 1.0 : 0.0;
    trainAccWindow.add(train_acc);
  }
  
  

  xLossWindow.add(lossx);
  wLossWindow.add(lossw);

  // visualize training status
  var train_elt = document.getElementById("trainstats");
  train_elt.innerHTML = '';
  var t = 'Forward time per example: ' + stats.fwd_time + 'ms';
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Backprop time per example: ' + stats.bwd_time + 'ms';
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Classification loss: ' + f2t(xLossWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  
  var t = 'Time per step: ' + (timeAccWindow.get_average().toFixed(0)+'ms');
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));

  var t = 'Time to generate: ' + (genAccWindow.get_average().toFixed(0)+'ms');
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));

  var t = 'L2 Weight decay loss: ' + f2t(wLossWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Training accuracy: ' + f2t(trainAccWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Validation accuracy: ' + f2t(valAccWindow.get_average());
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));
  var t = 'Examples seen: ' + step_num;
  train_elt.appendChild(document.createTextNode(t));
  train_elt.appendChild(document.createElement('br'));

  // visualize activations
  if(step_num % 100 === 0) {
    var vis_elt = document.getElementById("visnet");
    visualize_activations(net, vis_elt);
  }

  // log progress to graph, (full loss)
  if(step_num % 200 === 0) {
    var xa = xLossWindow.get_average();
    var xw = wLossWindow.get_average();
    if(xa >= 0 && xw >= 0) { // if they are -1 it means not enough data was accumulated yet for estimates
      lossGraph.add(step_num, xa + xw);
      lossGraph.drawSelf(document.getElementById("lossgraph"));
    }
  }

  // run prediction on test set
  if(step_num % 1000 === 0) {
    test_predict();
  }
  step_num++;
}

// user settings 
var change_lr = function() {
  trainer.learning_rate = parseFloat(document.getElementById("lr_input").value);
  update_net_param_display();
}
var change_momentum = function() {
  trainer.momentum = parseFloat(document.getElementById("momentum_input").value);
  update_net_param_display();
}
var change_batch_size = function() {
  trainer.batch_size = parseFloat(document.getElementById("batch_size_input").value);
  update_net_param_display();
}
var change_decay = function() {
  trainer.l2_decay = parseFloat(document.getElementById("decay_input").value);
  update_net_param_display();
}
var update_net_param_display = function() {
  document.getElementById('lr_input').value = trainer.learning_rate;
  document.getElementById('momentum_input').value = trainer.momentum;
  document.getElementById('batch_size_input').value = trainer.batch_size;
  document.getElementById('decay_input').value = trainer.l2_decay;
}
var toggle_pause = function() {
  paused = !paused;
  var btn = document.getElementById('buttontp');
  if(paused) { btn.value = 'resume' }
  else { btn.value = 'pause'; }
}
var dump_json = function() {
  document.getElementById("dumpjson").value = JSON.stringify(net.toJSON());
}



var clear_graph = function() {
  lossGraph = new cnnvis.Graph(); // reinit graph too 
}
var reset_all = function() {
  // trainer = new convnetjs.SGDTrainer(net, {learning_rate:trainer.learning_rate, momentum:trainer.momentum, batch_size:trainer.batch_size, l2_decay:trainer.l2_decay});

  update_net_param_display();

  // reinit windows that keep track of val/train accuracies
  xLossWindow.reset();
  wLossWindow.reset();
  trainAccWindow.reset();
  valAccWindow.reset();
  lossGraph = new cnnvis.Graph(); // reinit graph too
  step_num = 0;
}
var load_from_json = function() {
  var jsonString = document.getElementById("dumpjson").value;
  var json = JSON.parse(jsonString);
  change_net();
  net = new convnetjs.Net();
  net.fromJSON(json);

  reset_all();
}
var change_net = function() {
  eval($("#newnet").val());
  reset_all();
}

</script>
</head>
<body>
  <div id="wrap">
  <h2 style="text-align: center;"><a href="http://cs.stanford.edu/people/karpathy/convnetjs/">ConvNetJS</a> OCR demo</h2>
  <h1>Description</h1>
  <p>
    This demo trains a Convolutional Neural Network on the <a href="http://yann.lecun.com/exdb/mnist/">OCR digits dataset</a> in your browser, with nothing but Javascript. The dataset is fairly easy and one should expect to get somewhere around 99% accuracy within few minutes. I used <a href="mnist_parse.zip">this python script</a> to parse the <a href="http://deeplearning.net/tutorial/gettingstarted.html">original files</a> into batches of images that can be easily loaded into page DOM with img tags.
  </p>
  <p>
    This network takes a 28x28 OCR image and crops a random 24x24 window before training on it (this technique is called data augmentation and improves generalization). Similarly to do prediction, 4 random crops are sampled and the probabilities across all crops are averaged to produce final predictions. The network runs at about 5ms for both forward and backward pass on my reasonably decent Ubuntu+Chrome machine.
  </p>
  <p>
    By default, in this demo we're using Adadelta which is one of per-parameter adaptive step size methods, so we don't have to worry about changing learning rates or momentum over time. However, I still included the text fields for changing these if you'd like to play around with SGD+Momentum trainer.
  </p>
  <p>Report questions/bugs/suggestions to <a href="https://twitter.com/karpathy">@karpathy</a>.</p>
  <h1>Training Stats</h1>
  <div class="divsec" style="270px;">
    <div class="secpart">
      Current image: <img id="input_image" src=""></img><input id="buttontp" type="submit" value="pause" onclick="toggle_pause();"/>
      <div id="trainstats"></div>

      <div id="controls">
        Learning rate: <input name="lri" type="text" maxlength="20" id="lr_input"/>
        <input id="buttonlr" type="submit" value="change" onclick="change_lr();"/>
        <br />

        Momentum: <input name="momi" type="text" maxlength="20" id="momentum_input"/>
        <input id="buttonmom" type="submit" value="change" onclick="change_momentum();"/>
        <br />

        Batch size: <input name="bsi" type="text" maxlength="20" id="batch_size_input"/>
        <input id="buttonbs" type="submit" value="change" onclick="change_batch_size();"/>
        <br />

        Weight decay: <input name="wdi" type="text" maxlength="20" id="decay_input"/>
        <input id="buttonwd" type="submit" value="change" onclick="change_decay();"/>
      </div>

      <input id="buttondj" type="submit" value="save network snapshot as JSON" onclick="dump_json();"/><br />
      <input id="buttonlfj" type="submit" value="init network from JSON snapshot" onclick="load_from_json();"/><br />
      <textarea id="dumpjson"></textarea>
    </div>
    <div class="secpart">
      
      <div>
        Loss:<br />
        <canvas id="lossgraph">
        </canvas>
        <br />
        <input id="buttoncg" type="submit" value="clear graph" onclick="clear_graph();"/>
      </div>
    </div>
    <div style="clear:both;"></div>
  </div>

  <h1>Instantiate a Network and Trainer</h1>
  <div>
    <textarea id="newnet" style="width:100%; height:200px;"></textarea><br />
    <input id="buttonnn" type="submit" value="change network" onclick="change_net();" style="width:200px;height:30px;"/>
  </div>

  <div class="divsec">
  <h1>Network Visualization</h1>
    <div id="visnet"></div>
  </div>
  
  <div class="divsec">
  <h1>Example predictions on Test set</h1>
    <div id="testset_acc"></div>
  </div>

  </div>  
</body>
</html>



